# teacher2

一个面向英语学习的本地 Web 应用：输入一句/一段英语，AI 自动提取难词并生成测验卡片；用户作答后，把错题（生词 + 错误累计次数）写入本地 `langchain_history.json`，并提供历史日志与生词本管理。

## 核心流程

1. 输入句子（首页输入框）
2. 调用 AI 分析：抽取最多 8 个难词 + 中文释义 + 4 个干扰项 + 来源猜测
3. 前端以「逐词测验卡片」方式出题
4. 提交作答结果：仅把答错的词写入历史（并维护累计错误次数）
5. 在「历史日志」中查看记录，并在句子中高亮相关单词；在「生词本」中查看/删除生词

## 主要特性

### AI 分析与测验

- 难词提取：优先名词/动词/形容词，倾向更长、更难的词汇（上限 8 个）
- 测验卡片：每个词 1 个正确中文释义 + 4 个错误释义（前端随机打乱选项）
- 结果统计：只保存错题；全对则不写入历史
- Token 统计展示：在页面上展示本次调用的 token 使用情况
- 来源猜测：尝试给出句子可能出处（不保证准确）

### 历史日志

- 历史记录持久化：写入 `langchain_history.json`（每条记录包含时间、句子、来源、错题词汇与累计次数）
- 日期筛选：按起止日期过滤历史记录
- JSON 下载：把当前筛选结果下载为 JSON
- 单词高亮：历史日志里会把该条记录的词汇在句子中用绿色加粗高亮

### 生词本

- 生词聚合统计：从 `langchain_history.json` 中按时间顺序“更新每个词的最新累计次数”，并按次数降序展示
- 删除生词：点击每个词前的矢量垃圾桶图标，直接从 `langchain_history.json` 中删除该词
- 自动清理：若某条历史记录中 `vocabulary` 被删空，则整条历史记录（该句子）会被删除

### 对外打开与自动提交

- `/open/api/analyz`：支持外部以 POST JSON 方式传入 `sentence`，服务端会重定向到首页并自动填入/触发分析

## 页面与入口

- 首页 `/`：输入句子、进行测验；包含 Tab：
  - `[ 实时日志 ]`：展示测验与结果
  - `[ 历史日志 ]`：查看与筛选历史记录
  - `[ 生词本 ]`：查看生词统计与删除
- 独立历史页 `/history`：单页查看历史日志（含筛选与下载）

## HTTP API

| 方法 | 路径 | 用途 |
|---|---|---|
| `POST` | `/api/analyze` | AI 分析句子，返回难词测验数据与 token usage |
| `POST` | `/api/submit_quiz` | 提交测验作答结果，写入错题历史 |
| `GET` | `/api/history` | 按日期范围获取历史记录（`start_date`, `end_date`） |
| `GET` | `/api/check_history` | 聚合统计生词（按次数降序） |
| `POST` | `/api/delete_word` | 删除指定生词（可选 `dry_run`） |
| `POST` | `/open/api/analyz` | 外部打开首页并自动提交句子 |

## 数据存储（`langchain_history.json`）

`langchain_history.json` 是一个数组，每条元素形如：

```json
{
  "timestamp": "2025-12-16 12:36:10",
  "sentence": "...",
  "source": "...",
  "vocabulary": {
    "example": 2,
    "another": 1
  }
}
```

- `vocabulary` 的 value 是“累计错误次数”（不是增量）
- 生词本展示的是“每个词在时间序列中出现的最新累计次数”，并按次数降序排序

## 运行与配置

### 依赖

- Python 依赖见 `requirements.txt`

### 环境变量

- `SILICONFLOW_API_KEY`：用于调用大模型（`assistant.py` 中通过 `ChatOpenAI` 初始化）

### 启动

在项目根目录执行：

```bash
python3 app.py
```

默认监听 `0.0.0.0:5010`。

如果 `cert/cert.pem` 与 `cert/key.pem` 存在，会尝试配置 SSL 上下文（见 `app.py`）。
